{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import pythainlp\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import attacut ไม่ได้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokenizer = pythainlp.sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe\n",
    "df = pd.DataFrame(\n",
    "    {\"prompt_id\":[],\n",
    "    \"prompt\":[],\n",
    "    \"first_letter\":[],\n",
    "    \"next_word\":[]}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnn_path = \"/Users/natanan/Documents/GitHub/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_path = \"Powerful-N-Gram-Model-Distillation-of-Thai-Language-Model-with-N-Gram/Datasets/documents-nsc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_files_path = nnn_path + \"Powerful-N-Gram-Model-Distillation-of-Thai-Language-Model-with-N-Gram/Datasets/Training for N-gram/used_files.txt\"\n",
    "with open(used_files_path) as f:\n",
    "    used_files = {name.strip() for name in f}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(used_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_content(used_files, directory):\n",
    "    # Define the regular expression pattern\n",
    "    pattern = r'<doc id=\"[\\d]+\" url=\"[^\"]+\" title=\"[^\"]+\">(.+?)</doc>'\n",
    "    compiled_pattern = re.compile(pattern, re.DOTALL)\n",
    "\n",
    "    # Get a list of all files in the directory\n",
    "    all_files = [filename for filename in os.listdir(directory) if filename.endswith(\".txt\")]\n",
    "\n",
    "    # Shuffle the list of files randomly\n",
    "    random.seed(42)\n",
    "    random.shuffle(all_files)\n",
    "\n",
    "    # Remove all used files\n",
    "    unused_files = [file for file in all_files if file not in used_files]\n",
    "\n",
    "    # Initialize an empty string to store the combined [str_content]\n",
    "    combined_str_content = ''\n",
    "\n",
    "    # Initialize an empty list to store file names\n",
    "    used_file_names = []\n",
    "\n",
    "    # Store total words\n",
    "    sent_count = 0\n",
    "\n",
    "    # store sentences\n",
    "    sent_list = []\n",
    "\n",
    "    # Iterate through selected files\n",
    "    for filename in unused_files:\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        \n",
    "\n",
    "        # Open the file and read its content\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            file_content = file.read()\n",
    "\n",
    "            # Use regular expression to extract [str_content]\n",
    "            str_contents = compiled_pattern.findall(file_content)\n",
    "\n",
    "            # Iterate through each content and count sentences\n",
    "            for content in str_contents:\n",
    "                sents = sent_tokenizer(content)\n",
    "                for sent in sents:\n",
    "                    if sent_count < 100000:\n",
    "                        tokenized_sent = pythainlp.word_tokenize(sent)\n",
    "                        if len(tokenized_sent)>5:\n",
    "                            sent_list.append(tokenized_sent)\n",
    "                            sent_count += 1\n",
    "                            if filename not in used_file_names:\n",
    "                                used_file_names.append(filename)  # Record the used file name\n",
    "                        else:\n",
    "                            break  # Stop adding content if the token count exceeds 10000\n",
    "                \n",
    "        if sent_count >= 100000:\n",
    "            break  # Stop iterating through files if the token count exceeds 10000\n",
    "\n",
    "    # Write the used file names to a separate file\n",
    "    used_files_path = os.path.join(\"/Users/natanan/Documents/GitHub/Powerful-N-Gram-Model-Distillation-of-Thai-Language-Model-with-N-Gram/Datasets/Predictive Keyboard\", \"used_files_for_test.txt\")\n",
    "    with open(used_files_path, 'w', encoding='utf-8') as used_files:\n",
    "        for file_name in used_file_names:\n",
    "            used_files.write(file_name + '\\n')\n",
    "\n",
    "    print(\"Total sent is \", str(sent_count))\n",
    "    print(\"Used file names written to\", used_files_path)\n",
    "\n",
    "    return sent_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2k/kwdbvggj4g359ml99lzb7ch80000gn/T/ipykernel_4223/386985624.py:1: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  random.sample(used_files, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['372936.txt', '191841.txt', '21757.txt']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(used_files, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sent is  100000\n",
      "Used file names written to /Users/natanan/Documents/GitHub/Powerful-N-Gram-Model-Distillation-of-Thai-Language-Model-with-N-Gram/Datasets/Predictive Keyboard/used_files_for_test.txt\n"
     ]
    }
   ],
   "source": [
    "data = extract_content(used_files, nnn_path+doc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['สมาชิกสภาผู้แทนราษฎร', 'จังหวัด', 'บึงกาฬ', ' ', 'สมาชิกสภาผู้แทนราษฎร', 'จังหวัด', 'บึงกาฬ', ' '], ['มี', ' ', '2', ' ', 'เขต', 'การเลือกตั้ง', ' ', '(', 'ปี', ' ', 'พ.ศ.', ' ', '2554', ')', ' ', 'และ', 'มี', 'สมาชิกสภาผู้แทนราษฎร', 'แบบ', 'แบ่ง', 'เขต', 'ได้', ' ', '2', ' ', 'คน', ' ', 'จาก', 'ทั้งหมด', ' ', '375', ' ', 'คน', 'ทั่วประเทศ', 'ใน', 'สภาผู้แทนราษฎร', 'ไทย', 'ประวัติศาสตร์', ' ', 'ประวัติศาสตร์', '.', ' ']]\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "print(data[:2])\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate on each list and put them into df\n",
    "sent_list = []\n",
    "predict_word_list = []\n",
    "first_letter_list = []\n",
    "doc_id_list = []\n",
    "id = 0\n",
    "for sent in data:\n",
    "    sentence_str = \"\"\n",
    "    id += 1\n",
    "    doc_id_list.append(id)\n",
    "    random.seed(42)\n",
    "    pd_ind = random.randrange(5,len(sent))\n",
    "    while sent[pd_ind] in \" .,!?;:'\\\"()[]{}+-*/=<>&$€£¥¢@#°©®•…—–\\_|~^%\":\n",
    "        pd_ind -= 1\n",
    "    predict_word_list.append(sent[pd_ind])\n",
    "    first_letter_list.append(sent[pd_ind][0])\n",
    "    for i in range(pd_ind):\n",
    "        sentence_str += sent[i]\n",
    "    sent_list.append(sentence_str)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "สมาชิกสภาผู้แทนราษฎรจังหวัดบึงกาฬ สมาชิกสภาผู้แทนราษฎรจังหวัด\n",
      "บึงกาฬ\n",
      "บ\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\n"
     ]
    }
   ],
   "source": [
    "print(sent_list[0])\n",
    "print(predict_word_list[0])\n",
    "print(first_letter_list[0])\n",
    "print(doc_id_list[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\"prompt_id\":doc_id_list,\n",
    "    \"prompt\":sent_list,\n",
    "    \"first_letter\":first_letter_list,\n",
    "    \"next_word\":predict_word_list}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>first_letter</th>\n",
       "      <th>next_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>สมาชิกสภาผู้แทนราษฎรจังหวัดบึงกาฬ สมาชิกสภาผู้...</td>\n",
       "      <td>บ</td>\n",
       "      <td>บึงกาฬ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>มี 2 เขตการเลือกตั้ง (ปี พ.ศ.</td>\n",
       "      <td>2</td>\n",
       "      <td>2554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>หลังจากประเทศไทยมีการเปลี่ยนแปลงการปกครองใน</td>\n",
       "      <td>ป</td>\n",
       "      <td>ปี</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>เมื่อวันที่ 15 พฤศจิกายน พ.ศ. 2476 โดยการเลือก...</td>\n",
       "      <td>ค</td>\n",
       "      <td>ครั้งแรก</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>โดยมีสมาชิกสภาผู้แทนราษฎรชุดแรก คือ นายยุทธ</td>\n",
       "      <td>พ</td>\n",
       "      <td>พงษ์</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>99996</td>\n",
       "      <td>ตำบลชัยจุมพล อำเภอลับแล จังหวัด</td>\n",
       "      <td>อ</td>\n",
       "      <td>อุตรดิตถ์</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>99997</td>\n",
       "      <td>บางครั้งคนไทยเรียกว่าวัดน้ำใสตามคำแปลของ</td>\n",
       "      <td>ช</td>\n",
       "      <td>ชื่อ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>99998</td>\n",
       "      <td>อุ่นไอรัก หัวใจดวง</td>\n",
       "      <td>เ</td>\n",
       "      <td>เดิม</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>99999</td>\n",
       "      <td>อุ่นไอรัก...หัวใจดวงเดิม (; ) เป็นละครแนวรักโร...</td>\n",
       "      <td>อ</td>\n",
       "      <td>ออกอากาศ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>100000</td>\n",
       "      <td>เขียนบทโดย ชอยโฮยุน ผลิตโดย คิมชุ</td>\n",
       "      <td>ล</td>\n",
       "      <td>ลกิล</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       prompt_id                                             prompt  \\\n",
       "0              1  สมาชิกสภาผู้แทนราษฎรจังหวัดบึงกาฬ สมาชิกสภาผู้...   \n",
       "1              2                     มี 2 เขตการเลือกตั้ง (ปี พ.ศ.    \n",
       "2              3        หลังจากประเทศไทยมีการเปลี่ยนแปลงการปกครองใน   \n",
       "3              4  เมื่อวันที่ 15 พฤศจิกายน พ.ศ. 2476 โดยการเลือก...   \n",
       "4              5        โดยมีสมาชิกสภาผู้แทนราษฎรชุดแรก คือ นายยุทธ   \n",
       "...          ...                                                ...   \n",
       "99995      99996                    ตำบลชัยจุมพล อำเภอลับแล จังหวัด   \n",
       "99996      99997           บางครั้งคนไทยเรียกว่าวัดน้ำใสตามคำแปลของ   \n",
       "99997      99998                                 อุ่นไอรัก หัวใจดวง   \n",
       "99998      99999  อุ่นไอรัก...หัวใจดวงเดิม (; ) เป็นละครแนวรักโร...   \n",
       "99999     100000                  เขียนบทโดย ชอยโฮยุน ผลิตโดย คิมชุ   \n",
       "\n",
       "      first_letter  next_word  \n",
       "0                บ     บึงกาฬ  \n",
       "1                2       2554  \n",
       "2                ป         ปี  \n",
       "3                ค   ครั้งแรก  \n",
       "4                พ       พงษ์  \n",
       "...            ...        ...  \n",
       "99995            อ  อุตรดิตถ์  \n",
       "99996            ช       ชื่อ  \n",
       "99997            เ       เดิม  \n",
       "99998            อ   ออกอากาศ  \n",
       "99999            ล       ลกิล  \n",
       "\n",
       "[100000 rows x 4 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/Users/natanan/Documents/GitHub/Powerful-N-Gram-Model-Distillation-of-Thai-Language-Model-with-N-Gram/Datasets/Predictive Keyboard/test_set.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
